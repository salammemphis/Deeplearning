{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Input, BatchNormalization\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "X_train=X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1)\n",
    "X_test=X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1)\n",
    "\n",
    "#one-hot encode target column\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(np.unique(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f766c099d08> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f766c099d08> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/118 [..............................] - ETA: 2s - loss: 3.2241 - accuracy: 0.0820WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0149s vs `on_train_batch_end` time: 0.0235s). Check your callbacks.\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1546 - accuracy: 0.9603WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f77189050d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f77189050d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "118/118 [==============================] - 5s 38ms/step - loss: 0.1545 - accuracy: 0.9603 - val_loss: 0.1455 - val_accuracy: 0.9648\n",
      "Epoch 2/10\n",
      "118/118 [==============================] - 4s 37ms/step - loss: 0.0530 - accuracy: 0.9865 - val_loss: 0.0598 - val_accuracy: 0.9850\n",
      "Epoch 3/10\n",
      "118/118 [==============================] - 4s 37ms/step - loss: 0.0458 - accuracy: 0.9893 - val_loss: 0.0489 - val_accuracy: 0.9889\n",
      "Epoch 4/10\n",
      "118/118 [==============================] - 4s 37ms/step - loss: 0.0263 - accuracy: 0.9930 - val_loss: 0.1131 - val_accuracy: 0.9802\n",
      "Epoch 5/10\n",
      "118/118 [==============================] - 4s 37ms/step - loss: 0.0324 - accuracy: 0.9927 - val_loss: 0.0858 - val_accuracy: 0.9860\n",
      "Epoch 6/10\n",
      "118/118 [==============================] - 4s 36ms/step - loss: 0.0195 - accuracy: 0.9949 - val_loss: 0.0653 - val_accuracy: 0.9888\n",
      "Epoch 7/10\n",
      "118/118 [==============================] - 4s 37ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.0695 - val_accuracy: 0.9888\n",
      "Epoch 8/10\n",
      "118/118 [==============================] - 4s 37ms/step - loss: 0.0114 - accuracy: 0.9971 - val_loss: 0.0907 - val_accuracy: 0.9862\n",
      "Epoch 9/10\n",
      "118/118 [==============================] - 4s 37ms/step - loss: 0.0108 - accuracy: 0.9971 - val_loss: 0.0704 - val_accuracy: 0.9876\n",
      "Epoch 10/10\n",
      "118/118 [==============================] - 4s 37ms/step - loss: 0.0126 - accuracy: 0.9966 - val_loss: 0.0853 - val_accuracy: 0.9873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f77189919b0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128,kernel_size=3,activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D())\n",
    "model.add(Conv2D(256, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256,kernel_size=3,activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics='accuracy')\n",
    "model.fit(X_train,y_train, validation_data=(X_test,y_test), epochs=10,batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
