{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Input, BatchNormalization\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "X_train=X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1)\n",
    "X_train=X_train/255\n",
    "X_test=X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1)\n",
    "X_test=X_test/255\n",
    "\n",
    "#one-hot encode target column\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(np.unique(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa93de476a8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa93de476a8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  2/118 [..............................] - ETA: 6s - loss: 2.0190 - accuracy: 0.4004WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0246s vs `on_train_batch_end` time: 0.0423s). Check your callbacks.\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1590 - accuracy: 0.9589WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa93dd48510> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa93dd48510> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "118/118 [==============================] - 8s 69ms/step - loss: 0.1588 - accuracy: 0.9589 - val_loss: 11.7748 - val_accuracy: 0.1135\n",
      "Epoch 2/10\n",
      "118/118 [==============================] - 8s 66ms/step - loss: 0.0532 - accuracy: 0.9858 - val_loss: 12.5228 - val_accuracy: 0.1135\n",
      "Epoch 3/10\n",
      "118/118 [==============================] - 8s 68ms/step - loss: 0.0467 - accuracy: 0.9889 - val_loss: 2.3529 - val_accuracy: 0.4789\n",
      "Epoch 4/10\n",
      "118/118 [==============================] - 8s 68ms/step - loss: 0.0312 - accuracy: 0.9918 - val_loss: 0.1151 - val_accuracy: 0.9694\n",
      "Epoch 5/10\n",
      "118/118 [==============================] - 8s 68ms/step - loss: 0.0251 - accuracy: 0.9934 - val_loss: 0.0601 - val_accuracy: 0.9875\n",
      "Epoch 6/10\n",
      "118/118 [==============================] - 8s 68ms/step - loss: 0.0223 - accuracy: 0.9943 - val_loss: 0.0571 - val_accuracy: 0.9899\n",
      "Epoch 7/10\n",
      "118/118 [==============================] - 8s 68ms/step - loss: 0.0174 - accuracy: 0.9955 - val_loss: 0.0447 - val_accuracy: 0.9906\n",
      "Epoch 8/10\n",
      "118/118 [==============================] - 8s 69ms/step - loss: 0.0155 - accuracy: 0.9961 - val_loss: 0.0422 - val_accuracy: 0.9918\n",
      "Epoch 9/10\n",
      "118/118 [==============================] - 8s 70ms/step - loss: 0.0159 - accuracy: 0.9962 - val_loss: 0.0589 - val_accuracy: 0.9906\n",
      "Epoch 10/10\n",
      "118/118 [==============================] - 8s 71ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.0630 - val_accuracy: 0.9893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa93de605f8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128,kernel_size=3,activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D())\n",
    "model.add(Conv2D(256, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256,kernel_size=3,activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics='accuracy')\n",
    "model.fit(X_train,y_train, validation_data=(X_test,y_test), epochs=10,batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
